> 该系列文章基于 `github.com/shareAI-lab/learn-claude-code` 写就，该仓库以大道至简的风格剖析了Claude Code的核心原理，值得大家学习。由于该仓库是基于Python语言，为方便.NET开发者学习，我已经将代码基于.NET 10的`dotnet file` 重写，源码已上传至github，源码地址见文末。

# v5: 上下文压缩 - 三层管道让智能体无限工作

> 本文是 Learn Claude Code (C# 版) 系列的第六篇，对应代码文件 `v5_context_compact.cs`。

## 问题：上下文窗口有限

v4 给了我们技能加载，模型可以按需获取领域知识。但有个更基础的问题：

**上下文窗口是有限的。**

200,000 token 的上下文窗口听起来很大，但一次 `read_file` 读取 1000 行源文件就消耗约 4000 token。读取 30 个文件、运行 20 条 bash 命令后，你就已经用掉 100,000+ token 了。

```
工具调用积累 → 消息数组膨胀 → 超过上下文限制 → API 直接失败
```

即使在到达硬限制之前，性能也会下降：模型变慢、准确率降低、开始忽略早期消息。没有某种压缩机制，智能体无法在大型代码库上工作。

## 解决方案：三层压缩管道

三层管道以递增的激进程度来应对这个问题：

```
Every turn:
+------------------+
| Tool call result |
+------------------+
        |
        v
[Layer 1: MicroCompact]        (静默, 每轮执行)
  替换 3 轮之前的 tool_result
  为 "[Previous: used {tool_name}]"
        |
        v
[Check: tokens > 50000?]
   |               |
   no              yes
   |               |
   v               v
continue    [Layer 2: AutoCompact]
              保存对话记录到 .transcripts/
              LLM 摘要整个对话
              用 [summary] 替换所有消息
                    |
                    v
            [Layer 3: compact 工具]
              模型显式调用 compact
              触发相同的摘要机制
```

## 第一层：MicroCompact - 静默替换

每次 LLM 调用前，找到最近 3 条之前的所有 `tool_result` 条目，替换其内容为占位符：

```csharp
static void MicroCompact(List<MessageParam> messages)
{
    // 找到所有 tool_result
    var toolResults = new List<(int msgIdx, int partIdx, ToolResultBlockParam part)>();
    // ... 收集所有 tool_result ...

    if (toolResults.Count <= KEEP_RECENT) return;

    // 替换旧的 tool_result (保留最近 3 个)
    var toClear = toolResults.Take(toolResults.Count - KEEP_RECENT);
    foreach (var (_, _, part) in toClear)
    {
        if (part.Content?.Length > 100)
        {
            var toolName = toolNameMap.GetValueOrDefault(part.ToolUseID ?? "", "unknown");
            part.Content = $"[Previous: used {toolName}]";
        }
    }
}
```

关键洞察：**遗忘是特性而非缺陷**。旧的工具输出对当前任务通常已无关紧要。

## 第二层：AutoCompact - 阈值触发

当估算 token 超过 50,000 时，保存完整对话记录并请求 LLM 进行摘要：

```csharp
static async Task<List<MessageParam>> AutoCompactAsync(List<MessageParam> messages)
{
    // 1. 保存原始对话到 .transcripts/
    var transcriptPath = Path.Combine(transcriptDir, $"transcript_{ts}.jsonl");
    // ... 写入完整对话记录 ...

    // 2. 请求 LLM 摘要
    var response = await client.Messages.Create(new MessageCreateParams
    {
        Messages = [new() { Role = Role.User,
            Content = "Summarize this conversation..." + text }],
        MaxTokens = 2000
    });

    // 3. 用摘要替换所有消息
    return [
        new() { Role = Role.User, Content = $"[Compressed]\n\n{summary}" },
        new() { Role = Role.Assistant, Content = "Understood. Continuing." }
    ];
}
```

转录文件将完整历史保存在磁盘上，**没有任何东西真正丢失**，只是从活跃上下文中移出。

## 第三层：compact 工具 - 手动触发

`compact` 工具让模型或用户显式触发压缩，使用与 AutoCompact 相同的摘要机制：

```csharp
"compact" => {
    messages.Clear();
    messages.AddRange(await AutoCompactAsync(messages));
    return "Conversation compacted.";
}
```

## Token 估算

使用粗略的字符数/4 启发式方法：

```csharp
static int EstimateTokens(List<MessageParam> messages)
{
    // ~4 chars per token (rough estimate)
    return totalChars / 4;
}
```

教学简化说明：生产系统使用专业的 tokenizer 库进行精确计数。

## Agent Loop 整合

```csharp
while (true)
{
    MicroCompact(messages);                        // Layer 1: 每轮静默清理

    if (EstimateTokens(messages) > THRESHOLD)      // Layer 2: 阈值触发
        messages = await AutoCompactAsync(messages);

    var response = await client.Messages.Create(...);

    // ... 工具执行 ...

    if (manualCompact)                             // Layer 3: 手动触发
        messages = await AutoCompactAsync(messages);
}
```

## 相对 v4 的变更

| 组件 | 之前 (v4) | 之后 (v5) |
|------|-----------|-----------|
| Tools | 5 (含 skills) | 5 (基础 + compact) |
| 上下文管理 | 无 | 三层压缩 |
| Micro-compact | 无 | 旧结果 → 占位符 |
| Auto-compact | 无 | Token 阈值触发 |
| Manual compact | 无 | `compact` 工具 |
| Transcripts | 无 | 保存到 `.transcripts/` |

## 设计原理

上下文窗口有限，但智能体会话可以无限。三层压缩在不同粒度上解决这个问题：MicroCompact（替换旧工具输出）、AutoCompact（接近限制时 LLM 摘要）、Manual Compact（用户触发）。

分层方法让每一层在各自的粒度上独立运作，从静默的逐轮清理到完整的对话重置。

## 运行

```bash
dotnet run v5_context_compact.cs
```

可以尝试的提示：
1. `Read every C# file in the current directory one by one`（观察 MicroCompact 替换旧的结果）
2. `Keep reading files until compression triggers automatically`
3. `Use the compact tool to manually compress the conversation`
